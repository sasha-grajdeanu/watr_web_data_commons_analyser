<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>Scholarly Technical Report</title>
    <link rel="stylesheet" href="css/scholarly.min.css" />
    <script src="js/scholarly.min.js"></script>
  </head>
  <body prefix="schema: http://schema.org">
    <header>
      <h1>Web Data Commons Analyzer</h1>
    </header>

    <div role="contentinfo">
      <dl>
        <dt>Authors</dt>
        <dd>Alexandru-Cristian Grăjdeanu &amp; Maria Nestor</dd>

        <!-- <dt>License (OARE TREBUIE??)</dt>
        <dd>
          <a href="http://creativecommons.org/licenses/by/4.0/">CC-BY</a>
        </dd> -->
      </dl>
    </div>
    <section typeof="sa:Abstract" id="abstract" role="doc-abstract">
      <h2>Abstract</h2>
      <p>
        The Web Data Commons Analyzer (WATR) is a web-based application designed
        to process and analyze metadata extracted from the
        <a role="doc-biblioref">Web Data Commons</a>. Through this platform,
        users can perform complex tasks such as visualizing the structure and
        relationships within the data, classifying it according to predefined
        categories, comparing data, and aligning the data with existing
        ontologies. The system uses <a role="doc-biblioref">SPARQL</a> queries
        to a <a role="doc-biblioref">Apache Jena Fuseki</a> server to retrieve
        the data, and results are available in HTML,
        <a role="doc-biblioref">JSON-LD</a> and JSON formats. Various statistics
        for each operation are provided using the
        <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
      </p>
    </section>
    <section id="introduction" role="doc-introduction">
      <h2>Introduction</h2>
      <p>
        With the increasing amount of metadata embedded in web pages, effective
        processing and analysis tools are essential for extracting meaningful
        insights. The Web Data Commons Analyzer (WATR) is a web-based
        application designed to process and analyze metadata extracted from the
        <a role="doc-biblioref">Web Data Commons</a>. The platform enables users
        to perform four key operations on <a role="doc-biblioref">RDFa</a> and
        <a role="doc-biblioref">HTML5</a> microdata: visualization,
        classification, comparison, and alignment. These operations allow users
        to gain insights into the structure of the data, classify it according
        to predefined categories, compare datasets, and align them with existing
        ontologies.
      </p>

      <p>
        The system is structured into distinct modules, each dedicated to a
        specific task:
      </p>

      <ul>
        <li>
          Visualization, for exploring metadata structures and relationships.
        </li>
        <li>
          Classification, for categorizing metadata based on subject and
          predicate
        </li>
        <li>Comparison, for comparing two classes from the dataset, showing the common and unique properties.</li>
        <li>
          Alignment, for mapping metadata to existing ontologies, using
          <a role="doc-biblioref">AgreementMakerLight (AML)</a>
        </li>
      </ul>

      <p>
        The backend is implemented in <a role="doc-biblioref">Flask</a>, serving
        data from <a role="doc-biblioref">Apache Jena Fuseki</a> SPARQL
        endpoint, while the frontend is build using React for an interactive
        user experience.
      </p>

      <p>
        This report provides an in-depth look at the system architecture, the
        data structures used, the API implementation, and how external data
        sources are integrated. Furthermore, it discusses the technical details
        behind each operation and the challenges encountered during development.
      </p>
    </section>

    <section id="data-structures">
      <h2>Internal Data Structures</h2>

      <p>
        The application processes data in RDF format, specifically
        <a role="doc-biblioref">RDFa</a> and
        <a role="doc-biblioref">HTML5</a> microdata collected from the
        <a role="doc-biblioref">Web Data Commons</a>. This data is stored in an
        <a role="doc-biblioref">Apache Jena Fuseki</a> server, a robust RDF
        storage system that allows for efficient querying and manipulation of
        RDF data. The datasets are stored in the
        <code>/watr-dataset</code> dataset in
        <a role="doc-biblioref">Apache Jena Fuseki</a>.
      </p>

      <h3>Data Models and Structure</h3>
      <p>
        WATR utilizes several key data models to handle and represent metadata:
      </p>

      <ol>
        <li>
          RDF Data Models<br />
          The core data used by the application follows the Resource Description
          Framework (RDF), a specification that encodes data in a graph
          structure consisting of subject-predicate-object triples. This allows
          for the representation of relationships between entities. The data is
          provided in <a role="doc-biblioref">N-Quads</a> format, which is a
          serialization of RDF that supports the inclusion of multiple graphs in
          a single file.
        </li>
        <li>
          Preprocessed RDF Data<br />
          The metadata is extracted and preprocessed by the
          <a role="doc-biblioref">Web Data Commons</a> team from
          <a role="doc-biblioref">RDFa</a> and
          <a role="doc-biblioref">HTML5</a> microdata embedded pages. This
          metadata is then made available in
          <a role="doc-biblioref">N-Quads</a> format (files with the .nq
          extension). The WATR application will consume this data for its
          analysis.
        </li>
      </ol>

      <h3>Database and Data Access</h3>
      <p>
        The RDF datasets are stored in an
        <a role="doc-biblioref">Apache Jena Fuseki</a> server, which serves as
        the primary (and only) RDF database of the application. The database is
        structured into a dataset named /watr-dataset, where all the metadata
        from the <a role="doc-biblioref">Web Data Commons</a> is stored.
      </p>

      <p>
        Data access is achieved using
        <a role="doc-biblioref">SPARQL</a> queries, the query language designed
        for querying RDF datasets. Each operation (visualization,
        classification, comparison, and alignment) utilizes specific
        <a role="doc-biblioref">SPARQL</a> query patterns that are made
        specifically to retrieve relevant results from the dataset. These
        queries interact directly with the Fuseki server, enabling dynamic and
        real-time processing of metadata.
      </p>

      <h3>Data Flow and Access Patterns</h3>
      <p>
        The application fetches RDF data from the
        <a role="doc-biblioref">Apache Jena Fuseki</a> server based on user
        requests. <a role="doc-biblioref">SPARQL</a> queries are constructed
        based on the type of the operation:
      </p>
      <ul>
        <li>Visualization queries returns data based on a selected RDF class.</li>
        <li>
          Classification queries categorize the metadata based on selected
          subject-predicate relationships.
        </li>
        <li>Comparison queries extract the union between metadata returned from 
            two RDF classes and shows their common and unique properties.</li>
        <li>
          Alignment queries extracts the necessary metadata and structures in
          RDF format to be further processed by the backend.
        </li>
      </ul>
    </section>

    <section id="api">
      <h2>API Implementation</h2>

      <p>
        The application exposes a RESTful API implemented in
        <a role="doc-biblioref">Flask</a>. The API allows users to interact with
        the system and perform the four key operations: visualization,
        classification, comparison, and alignment. Each operation is associated
        with a set of endpoints that handle user input, execute
        <a role="doc-biblioref">SPARQL</a> queries, and return the results.
      </p>

      <p>Below is an overview of the endpoints exposed by the application:</p>
      <ol>
        <li>
          Visualization Operation:
          <ul>
            <li>
              <code>/api/visualise/data</code> - Visualise data in various
              formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)
            </li>
            <li>
              <code>/api/visualise/html</code> - Visualises the data filtered by
              the provided RDF class, with an optional limit and count limit,
              returning the data in an HTML format
            </li>
            <li>
              <code>/api/visualise/json_ld</code> - Visualises the data filtered
              by the provided RDF class, with an optional limit and count limit,
              returning the data in an
              <a role="doc-biblioref">JSON-LD</a> format
            </li>
            <li>
              <code>/api/visualise/graph</code> - Visualises the data filtered
              by the provided RDF class, with an optional limit and count limit,
              returning the data as a <a role="doc-biblioref">GraphML</a> file
            </li>
            <li>
              <code>/api/visualise/statistics</code> - Creates statistics for
              visualisation, such as the properties types and their
              distribution, types of entities within class, how many unique
              entities, and the value types distribution
            </li>
            <li>
              <code>/api/visualise/download_statistics</code> - This endpoint
              allows you to download visualisation statistics filtered by RDF
              class. You can also limit the number of returned items and specify
              a count limit.
            </li>
          </ul>
        </li>

        <li>
          Classification Operation:
          <ul>
            <li>
              <code>/api/classify/properties</code> - Having a RDF class, this
              endpoint returns the unique properties of that class.
            </li>
            <li>
              <code>/api/classify/data</code> - Classify the data filtered by
              the provided RDF class and property, returning the data in various
              formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)
            </li>
            <li>
              <code>/api/classify/html</code> - Classify the data filtered by
              the provided RDF class and property, returning the data in HTML
              format
            </li>
            <li>
              <code>/api/classify/json_ld</code> - Classify the data filtered by
              the provided RDF class and property, returning the data in
              <a role="doc-biblioref">JSON-LD</a> format.
            </li>
            <li>
              <code>/api/classify/graph</code> - Classify the data filtered by
              the provided RDF class and property, returning the data as a
              <a role="doc-biblioref">GraphML</a> file
            </li>
            <li>
              <code>/api/classify/statistics</code> - Creates statistics for
              classification, such as the depth of a subject-predicate pair, and
              the distribution of unique subjects.
            </li>
            <li>
              <code>/api/classify/statistics/graph</code> - Saves the statistics
              of the classification operation in temporary files, using
              <a role="doc-biblioref">RDF Data Cube vocabulary</a>, for further
              downloading
            </li>
          </ul>
        </li>

        <li>
          Comparison Operation:
          <ul>
            <li>
              <code>/api/compare/data</code> - Compare the data provided by two
              RDF classes, returning the result of the operation in various
              formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)
            </li>
            <li>
              <code>/api/compare/html</code> - Compare the data provided by two
              RDF classes, returning the result of the operation in HTML format
            </li>
            <li>
              <code>/api/compare/json_ld</code> - Compare the data provided by
              two RDF classes, returning the result of the operation in
              <a role="doc-biblioref">JSON-LD</a> format
            </li>
            <li>
              <code>/api/compare/statistics</code> - Creates statistics for
              comparison operation, such as the properties of each class, which
              is the last/most used property, how many properties, which are the
              unique properties (that don't appear in the other class), or which
              are the common properties
            </li>
            <li>
              <code>/api/compare/download_statistics</code> - This endpoint
              allows you to download comparison statistics.
            </li>
          </ul>
        </li>

        <li>
          Alignment Operation:
          <ul>
            <li>
              <code>/api/align/data</code> - Align the data to an ontology
              provided, returning the result of the operation in various formats
              (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)
            </li>
            <li>
              <code>/api/align/html</code> - Align the data to an ontology
              provided, returning the result of the operation in HTML format
            </li>
            <li>
              <code>/api/align/json_ld</code> - Align the data to an ontology
              provided, returning the result of the operation in
              <a role="doc-biblioref">JSON-LD</a> format
            </li>
            <li>
              <code>/api/align/table</code> - Align the data to an ontology
              provided, returning the result of the operation in JSON format, to
              further create a table
            </li>
            <li>
              <code>/api/align/statistics</code> - Create statistics for
              alignment operation, namely the average measure of the alignment
            </li>
            <li>
              <code>/api/align/statistics/graph</code> - Creates statistics in
              <a role="doc-biblioref">RDF Data Cube vocabulary</a> for alignment
              operation, and saves the results in a temporary file for further
              downloading
            </li>
          </ul>
        </li>

        <li>
          Other endpoints:
          <ul>
            <li>
              <code>/api/download-stats</code> - Sends the file as an
              attachment, where the file name is sent as parameter; it is used
              in Classification and Alignment operations
            </li>
          </ul>
        </li>
      </ol>

      <p>Below are some example requests for each operation:</p>

      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            # Examples of GET request to statistics visualisation endpoint
            GET api/visualise/statistics?class=AdministrativeArea&limit=true&count_limit=5
            Accept: application/json
            Response:
            {
              "properties_type": {
                "http://schema.org/address": 1,
                "http://schema.org/containsPlace": 1,
                "http://www.w3.org/1999/02/22-rdf-syntax-ns#type": 1
              },
              "type_entity": {
                "uri": 1
              },
              "unique_entities": 1,
              "value_type": {
                "bnode": 1,
                "uri": 2
              }
            }
  
          
            # Example of GET request to the main classification endpoint
            GET /api/classify?class=AdministrativeArea&property=schema:address
            Accept: */*
            Response:
            [
                {
                    "blankNode": "https://archiipedia.com/#PostalAddress",
                    "initial_predicate": "http://schema.org/address",
                    "initial_subject": "https://archiipedia.com/#AdministrativeArea",
                    "level1_object": "http://schema.org/PostalAddress",
                    "level1_predicate": "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"
                },
                {
                    "blankNode": "https://archiipedia.com/#PostalAddress",
                    "initial_predicate": "http://schema.org/address",
                    "initial_subject": "https://archiipedia.com/#AdministrativeArea",
                    "level1_object": "india",
                    "level1_predicate": "http://schema.org/addressCountry"
                }
              ...
            ]
          
            
              # Example of GET request to the properties endpoint
              GET /api/properties?class=AdministrativeArea
              Accept: */*
              Response:
              [
                  "rdf:type",
                  "schema:address",
                  "schema:containsPlace",
                  "schema:geo",
                  "schema:name",
                  "schema:url",
                  "schema:hasMap",
                  "schema:mainEntityOfPage",
                  "schema:sameAs"
              ]
  
          
            # Examples to GET request to the comparison statistics endpoint
            GET api/compare/statistics?class_one=AdministrativeArea&class_two=City
            Accept: application/json
            Response: 
            {
              "AdministrativeArea": {
                "least_used": "http://schema.org/address",
                "most_used": "http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
                "properties": [
                  "http://schema.org/address",
                  "http://schema.org/containsPlace",
                  "http://schema.org/name",
                  "http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
                  "http://schema.org/hasMap",
                  "http://schema.org/mainEntityOfPage",
                  "http://schema.org/geo",
                  "http://schema.org/url",
                  "http://schema.org/sameAs"
                ],
                "total_count": 9,
                "unique_properties": [
                  "http://schema.org/containsPlace",
                  "http://schema.org/geo"
                ]
              },
              "City": {
                "least_used": "http://schema.org/containedInPlace",
                "most_used": "http://schema.org/name",
                "properties": [
                  "http://schema.org/containedInPlace",
                  "http://schema.org/address",
                  "http://schema.org/longitude",
                  "http://schema.org/name",
                  "http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
                  "http://schema.org/hasMap",
                  "http://schema.org/mainEntityOfPage",
                  "http://schema.org/url",
                  "http://schema.org/sameAs",
                  "http://schema.org/latitude"
                ],
                "total_count": 10,
                "unique_properties": [
                  "http://schema.org/containedInPlace",
                  "http://schema.org/longitude",
                  "http://schema.org/latitude"
                ]
              },
              "common_properties": [
                "http://schema.org/address",
                "http://schema.org/name",
                "http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
                "http://schema.org/hasMap",
                "http://schema.org/mainEntityOfPage",
                "http://schema.org/url",
                "http://schema.org/sameAs"
              ]
            }
  
         
            # Example of GET request to the main alignment endpoint
            GET api/align?target=schema.org
            Accept: */*
            Response:
            C:\Users\ENBYSE~1\AppData\Local\Temp\tmpe_ck29uf.nt
  
            # Example of GET request to the results table generated for alignment operation
            GET api/align/table?target=schema.org
            Accept: */*
            Response:
            "results": [
                          {
                              "alignedEntity": "https://schema.org/Mountain",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/Mountain",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/JobPosting",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/JobPosting",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/State",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/State",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/Brand",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/Brand",
                              "relation": "="
                          }
                          ...
                        ]
          </code>
        </pre>
      </figure>
    </section>

    <section id="rdf-models">
      <h2>RDF-based Knowledge Models</h2>

      <p>
        The system is built upon RDF-based knowledge models, using structured
        semantic data to facilitate visualisation, classification, comparison,
        and alignment operations.
      </p>

      <h3>Data sources and Storage</h3>
      <p>
        The input RDF data is obtained from
        <a role="doc-biblioref">Web Data Commons</a> in
        <a role="doc-biblioref">N-Quads</a>
        format and consists of structured entities belonging to various RDF
        classes. These datasets are loaded into an
        <a role="doc-biblioref">Apache Jena Fuseki</a> server, using an
        additional tool built by us, namely
        <strong>FusekiPopulationTool</strong>
        which reads the URLs to the sample files, processes them, and adds them
        to the server. This allows efficient SPARQL querying and reasoning over
        RDF graphs.
      </p>

      <p>
        The samples from <a role="doc-biblioref">Web Data Commons</a> represent
        class-specific subsets of the <a role="doc-biblioref">schema.org</a>
        data. Some examples of those subsets are: AdministrativeArea, Airport,
        Book, CollegeOrUniveristy, Event, etc.
      </p>

      <h3>Ontology and Alignment</h3>
      <p>
        To ensure compatibility with widely used knowledge graphs, the system
        performs <strong>ontology alignment</strong> with external knowledge
        bases, specifically <a role="doc-biblioref">schema.org</a> and
        <a role="doc-biblioref">DBPedia</a>. This alignment process allows
        mapping entities and properties from the extracted RDF dataset to
        standard vocabularies, improving data integration and semantic
        consistency.
      </p>
      <p>
        For aligment, we use
        <a role="doc-biblioref">AgreementMakerLight (AML)</a>, an automated and
        efficient ontology matching system. It is primarily based on the use of
        element-level matching techniques.
      </p>
    </section>

    <section id="external-sources">
      <h2>External Data/Knowledge Sources</h2>

      <p>
        The system integrates external knowledge sources to enhance the
        interoperability of the RDF-based models. These sources provide
        structured data that support various operations, such as visualisation,
        classification, comparison, and alignment.
      </p>

      <h3>External Data Sources</h3>
      <p>
        The system primarily utilizes data from
        <a role="doc-biblioref">Web Data Commons</a>, which serves as the source
        of RDF data, organized in <a role="doc-biblioref">N-Quads</a> format.
        These datasets contain structured metadata extracted from the web,
        covering multiple entity types such as organizations, places, events,
        and products.
      </p>

      <p>
        The system also performs, besides other operations, the ontology
        alignment with widely used knowledge graphs,
        <a role="doc-biblioref">schema.org</a> and
        <a role="doc-biblioref">DBPedia</a>. These sources provide well-defined
        vocabularies and entity relationships.
      </p>

      <h3>SPARQL Queries for data extraction</h3>

      <p>
        Data stored in <a role="doc-biblioref">Apache Jena Fuseki</a> is queried
        using SPARQL to enable various processing tasks, including
        visualization, classification, comparison, and alignment.
      </p>

      <h4>Visualisation Operation</h4>
      <p>
        The system retireves instances of a given RDF class along with their
        properties and values, including blank nodes (bnodes) when applicable.
      </p>

      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;
            PREFIX schema: &lt;http://schema.org/&gt;
            SELECT ?entity ?property ?value ?bnodeProperty ?bnodeValue
            WHERE {{
              GRAPH ?graph {{ 
                ?entity rdf:type schema:{rdf_class};  
                        ?property ?value.  
                OPTIONAL {{
                  ?value ?bnodeProperty ?bnodeValue.
                  FILTER(isBlank(?value)) }} }} }}
          </code>
        </pre>
      </figure>

      <h4>Classification Operation</h4>
      <p>
        This operation classifies data based on an RDF class and property. To
        classify and analyze structured entities, the system expands RDF
        relationships across multiple levels, retrieving both direct and nested
        connections.
      </p>

      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;
            PREFIX schema: &lt;http://schema.org/&gt;
            SELECT ?initial_subject ?initial_predicate ?blankNode 
                  ?level1_predicate ?level1_object 
                  ?level2_predicate ?level2_object 
                  ?level3_predicate ?level3_object
            WHERE {{
                GRAPH ?graph {{
                    ?initial_subject rdf:type schema:{rdf_class} .  
                    ?initial_subject ?initial_predicate ?blankNode .  
                    FILTER (?initial_predicate = {property})
                    OPTIONAL {{
                        ?blankNode ?level1_predicate ?level1_object .
                        OPTIONAL {{
                            ?level1_object ?level2_predicate ?level2_object .
                            OPTIONAL {{
                                ?level2_object ?level3_predicate ?level3_object . 
                              }} }} }} }} }}
          </code>
        </pre>
      </figure>

      <h4>Comparison Operation</h4>
      <p>
        This query compares two RDF classes by extracting shared properties and
        counting their occurences in each class.
      </p>
      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            PREFIX schema: &lt;http://schema.org/&gt;
            PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;
            SELECT ?property (COUNT(DISTINCT ?class_one) AS ?class_one_count) 
                            (COUNT(DISTINCT ?class_two) AS ?class_two_count)
            WHERE {{
              GRAPH ?g {{
                {{ ?class_one a schema:{class_one} ; ?property [] }}
                UNION
                {{ ?class_two a schema:{class_two} ; ?property [] }}
              }}
            }}
            GROUP BY ?property
          </code>
        </pre>
      </figure>

      <h4>Alignment Operation</h4>
      <p>
        Ontology alignment is performed using
        <a role="doc-biblioref">AgreementMakerLight</a>, mapping extracted
        triples from Fuseki to <a role="doc-biblioref">schema.org</a> and
        <a role="doc-biblioref">DBPedia</a>. Instead of querying these
        ontologies online, we downloaded their RDF dumps and integrated them
        into our processing pipeline.
      </p>
      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            CONSTRUCT {
              ?s ?p ?o
            }
            WHERE {
                GRAPH ?g {
                    ?s ?p ?o .
                }
            }
          </code>
        </pre>
      </figure>
    </section>

    <section id="user-guide">
      <h2>User Guide</h2>
      <p>
        When opening the web application, the user will see the home page, where
        information about the project is displayed.
      </p>
      <p>From the navigation bar, they can select the following pages:</p>
      <subsection id="visualisation-guide">
        <h3>Visualisation</h3>
        <p>
          This page is dedicated to viewing data provided by <a role="doc-biblioref">Web Data Commons</a>.
          The user will fill out a form to select the class from which they want
          to view data, then choose whether they want to see all data related to
          the class or only a portion of it. If they select “true”, they must
          specify the desired number of records. If any form field is left
          empty, the user will be warned before submission.
        </p>
        <p>
          After submitting the form, a panel will appear on the right side,
          displaying a graph generated using the selected class's data, along
          with various statistics about the data (number of unique entities,
          properties, and their usage frequency, etc.).
        </p>
        <p>
          The user can download data files in various formats (HTML, <a role="doc-biblioref">JSON-LD</a>) as
          well as a file with the generated statistics, modeled using the 
          <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
        </p>
      </subsection>
      <subsection id="comparison-guide">
        <h3>Comparison</h3>
        <p>
          This page is dedicated to comparing two classes from the dataset
          provided by <a role="doc-biblioref">Web Data Commons</a>. The user will fill out a form to select
          two different classes for comparison. If any field is left empty or
          the user selects the same class twice, they will be warned before
          submitting the form.
        </p>
        <p>
          After submission, a panel will appear on the right side displaying a
          table showing the properties used by each class, their frequency, and
          various statistics about the comparison (common properties, unique
          properties for each class, the most used and least used properties).
        </p>
        <p>
          The user can download data files in various formats (HTML, <a role="doc-biblioref">JSON-LD</a>) as
          well as a file with the generated statistics, modeled using the <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
        </p>
      </subsection>
      <subsection id="classification-guide">
        <h3>Classification</h3>
        <p>
          This page allows the classification of data provided by <a role="doc-biblioref">Web Data Commons</a> 
          based on class and property. The user will fill out a form to
          select a class and a property for classification. If any field is left
          empty, the user will be warned before submitting the form.
        </p>
        <p>
          After submission, a panel will appear on the right side, displaying a
          graph generated using the provided data, along with various statistics
          about the data. The user can download data files in various formats
          (HTML, <a role="doc-biblioref">JSON-LD</a>) as well as files with the generated statistics,
          modeled using the <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
        </p>
      </subsection>
      <subsection id="alignment-guide">
        <h3>Alignment</h3>
        <p>
          This page is dedicated to aligning the data provided by <a role="doc-biblioref">Web Data Commons</a> 
          to an existing ontology. The user will fill out a form to
          select the ontology based on which the alignment will be performed. If
          any field is left empty, the user will be warned before submitting the
          form.
        </p>
        <p>
          After submission, a panel will appear on the right side displaying a
          table with the alignment results and an average of the aligned data.
          The user can download data files in various formats (HTML, <a role="doc-biblioref">JSON-LD</a>) as
          well as a file with the generated statistics, modeled using the <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
        </p>
      </subsection>
    </section>

    <section id="demonstration">
      <h2>Demonstration</h2>
      <p>link la demo</p>

      <p></p>
      <p>
        A demonstration of the WATR application is available at the following
        link:
        <a>WATR Demo</a>
      </p>
    </section>

    <section id="conclusions">
      <h2>Conclusions and Future Perspectives</h2>
      <h3>Challenges and Achievements</h3>
      <p>
        Thorought the development of this project, several challenges were encountered. 
        One of the rpimary difficulties was the integgration of heterogeneour RDF datasets extracted 
        from <a role="doc-biblioref">Web Data Commons</a>. The use of <a role="doc-biblioref">Apache Jena Fuseki</a> 
        facilitaed efficient <a role="doc-biblioref">SPARQL</a> querying, but handling inconsistences required additional 
        processing.
      </p>
      <p>
        Another significant challenge was implementing ontology alignment, where <a role="doc-biblioref">AgreementMakerLight (AML)</a> 
        was used to map RDF triples onto reference ontologies. This process helped improve 
        semantic consistency across different datasets, allowing better data interoperability and 
        integration.
      </p>
      <p> 
        Despite these challenges, the project successfully achieved its objectives:
      </p>
      <ul>
        <li>Developed a visualisation module for exporing RDF data interactively</li>
        <li>Implemented classification and comparison functionalities to analyze structured data</li>
        <li>Designed an ontology alignment mechanism for improving semantic interoperability</li>
        <li>Provided export capabilities in multiple formats, enhancing data usability.</li>
      </ul>

      <h3>Future Perspectives</h3>
      <p>
        The current system provides a solid foundation for RDF-based data exploration and ontology alignment, 
        but several improvements and extensions could be considered in future work:
      </p>
      <ul>
        <li>Enhanced ontology aligmnent techniques</li>
        <li>Support for real-time data updates, allowing dynamic <a role="doc-biblioref">SPARQL</a> querying on datasets</li>
        <li>Extension for other Linked Open Data sources, such as Wikidata</li>
        <li>Optimization of <a role="doc-biblioref">SPARQL</a> queries for improved performance</li>
      </ul>
      <p>
        By addressing these aspects, the system could evolve into a more comprehensive knowledge exploration and 
        semantic integration platform.
      </p>
    </section>
  </body>
</html>
