<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Scholarly Technical Report</title>
    <link rel="stylesheet" href="css/scholarly.min.css">
    <script src="js/scholarly.min.js"></script>
  </head>
  <body prefix="schema: http://schema.org">
    <header>
      <h1>Web Data Commons Analyzer</h1>
    </header>
    
    <div role="contentinfo">
      <dl>
        <dt>Authors</dt>
        <dd>
          Alexandru-Cristian GrÄƒjdeanu
          &amp;
          Maria Nestor
        </dd>

        <dt>License (OARE TREBUIE??)</dt>
        <dd>
          <a href="http://creativecommons.org/licenses/by/4.0/">CC-BY</a>
        </dd>
      </dl>
    </div>
    <section typeof="sa:Abstract" id="abstract" role="doc-abstract">
      <h2>Abstract</h2>
      <p>
        The Web Data Commons Analyzer (WATR) is a web-based application designed to process 
        and analyze metadata extracted from the <a role="doc-biblioref">Web Data Commons</a>. Through this platform, users 
        can perform complex tasks such as visualizing the structure and relationships within the data, 
        classifying it according to predefined categories, comparing data, and aligning the data with 
        existing ontologies. The system uses <a role="doc-biblioref">SPARQL</a> queries to a <a role="doc-biblioref">Apache Jena Fuseki</a> server to retrieve the data, and results 
        are available in HTML, <a role="doc-biblioref">JSON-LD</a> and JSON formats. Various statistics for each operation are provided using the
        <a role="doc-biblioref">RDF Data Cube vocabulary</a>.
      </p>
    </section>
    <section id="introduction" role="doc-introduction">
      <h2>Introduction</h2>
      <p>
        With the increasing amount of metadata embedded in web pages, effective processing and analysis tools
        are essential for extracting meaningful insights. The Web Data Commons Analyzer (WATR) is a web-based
        application designed to process and analyze metadata extracted from the <a role="doc-biblioref">Web Data Commons</a>. The platform enables
        users to perform four key operations on <a role="doc-biblioref">RDFa</a> and <a role="doc-biblioref">HTML5</a>  microdata: visualization, classification, comparison, and
        alignment. These operations allow users to gain insights into the structure of the data, classify
        it according to predefined categories, compare datasets, and align them with existing ontologies.
      </p>

      <p>
        The system is structured into distinct modules, each dedicated to a specific task:
      </p>

      <ul>
          <li>Visualization, for exploring metadata structures and relationships.</li>
          <li>Classification, for categorizing metadata based on subject and predicate</li>
          <li>Comparison, for </li>
          <li>Alignment, for mapping metadata to existing ontologies, using <a role="doc-biblioref">AgreementMakerLight (AML)</a></li>
        </ul>

      <p>
        The backend is implemented in <a role="doc-biblioref">Flask</a>, serving data from <a role="doc-biblioref">Apache Jena Fuseki</a>  SPARQL endpoint, while the frontend is build
        using React for an interactive user experience.
      </p>

      <p>
        This report provides an in-depth look at the system architecture, the data structures used, the API 
        implementation, and how external data sources are integrated. Furthermore, it discusses the technical 
        details behind each operation and the challenges encountered during development.
      </p>
    </section>
    
    <section id="data-structures">
      <h2>Internal Data Structures</h2>

      <p>
        The application processes data in RDF format, specifically <a role="doc-biblioref">RDFa</a> and <a role="doc-biblioref">HTML5</a>  microdata
        collected from the <a role="doc-biblioref">Web Data Commons</a>. This data is stored in an <a role="doc-biblioref">Apache Jena Fuseki</a> server, a robust
        RDF storage system that allows for efficient querying and manipulation of RDF data. The datasets are stored in the 
        <code>/watr-dataset</code> dataset in <a role="doc-biblioref">Apache Jena Fuseki</a>.
      </p>

      <h3>Data Models and Structure</h3>
      <p>
        WATR utilizes several key data models to handle and represent metadata:
      </p>

      <ol>
        <li>RDF Data Models<br>
          The core data used by the application follows the Resource Description
          Framework (RDF), a specification that encodes data in a graph structure consisting of
          subject-predicate-object triples. This allows for the representation of relationships between
          entities. The data is provided in <a role="doc-biblioref">N-Quads</a> format, which is a serialization of RDF that supports
          the inclusion of multiple graphs in a single file.
        </li>
        <li>Preprocessed RDF Data<br>
          The metadata is extracted and preprocessed by the <a role="doc-biblioref">Web Data Commons</a> team from <a role="doc-biblioref">RDFa</a> and <a role="doc-biblioref">HTML5</a>  microdata
          embedded pages. This metadata is then made available in <a role="doc-biblioref">N-Quads</a> format (files with the .nq extension).
          The WATR application will consume this data for its analysis.
        </li>
      </ol>

      <h3>Database and Data Access</h3>
      <p>
        The RDF datasets are stored in an <a role="doc-biblioref">Apache Jena Fuseki</a> server, which serves as the
        primary (and only) RDF database of the application. The database is structured into a dataset named
        /watr-dataset, where all the metadata from the <a role="doc-biblioref">Web Data Commons</a> is stored.
      </p>

      <p>
        Data access is achieved using <a role="doc-biblioref">SPARQL</a> queries, the query language designed for
        querying RDF datasets. Each operation (visualization, classification, comparison, and alignment)
        utilizes specific <a role="doc-biblioref">SPARQL</a> query patterns that are made specifically to retrieve
        relevant results from the dataset. These queries interact directly with the Fuseki server, enabling
        dynamic and real-time processing of metadata.
      </p>

      <h3>Data Flow and Access Patterns</h3>
      <p>
        The application fetches RDF data from the <a role="doc-biblioref">Apache Jena Fuseki</a> server based on user requests. <a role="doc-biblioref">SPARQL</a> queries
        are constructed based on the type of the operation:
      </p>
      <ul>
        <li>Visualization </li>
        <li>Classification queries categorize the metadata based on selected subject-predicate relationships.</li>
        <li>Comparison </li>
        <li>Alignment queries extracts the necessary metadata and structures in RDF format to be further processed by the backend.</li>
      </ul>

    </section>

    <section id="api">
      <h2>API Implementation</h2>

      <p>
        The application exposes a RESTful API implemented in <a role="doc-biblioref">Flask</a>. The API allows users to
        interact with the system and perform the four key operations: visualization, classification, comparison, 
        and alignment. Each operation is associated with a set of endpoints that handle user input, 
        execute <a role="doc-biblioref">SPARQL</a> queries, and return the results.
      </p>

      <p>Below is an overview of the endpoints exposed by the application:</p>
      <ol>
          <li>
            Visualization Operation:
            <ul>
              <li><code>/api/visualise/data</code> - Visualise data in various formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)</li>
              <li><code>/api/visualise/html</code> - Visualises the data filtered by the provided RDF class, with an optional limit and count limit, returning the data in an HTML format</li>
              <li><code>/api/visualise/json_ld</code> - Visualises the data filtered by the provided RDF class, with an optional limit and count limit, returning the data in an <a role="doc-biblioref">JSON-LD</a> format</li>
              <li><code>/api/visualise/graph</code> - Visualises the data filtered by the provided RDF class, with an optional limit and count limit, returning the data as a <a role="doc-biblioref">GraphML</a> file</li>
              <li><code>/api/visualise/statistics</code> - Creates statistics for visualisation, such as the properties types and their distribution, types of entities within class, how many unique entities, and the value types distribution</li>
              <li><code>/api/visualise/download_statistics</code> - This endpoint allows you to download visualisation statistics filtered by RDF class. You can also limit the number of returned items and specify a count limit.</li>
            </ul>
          </li>

          <li>
            Classification Operation:
            <ul>
                <li><code>/api/classify/properties</code> - Having a RDF class, this endpoint returns the unique properties of that class.</li>
                <li><code>/api/classify/data</code> - Classify the data filtered by the provided RDF class and property, returning the data in various formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)</li>
                <li><code>/api/classify/html</code> - Classify the data filtered by the provided RDF class and property, returning the data in HTML format</li>
                <li><code>/api/classify/json_ld</code> - Classify the data filtered by the provided RDF class and property, returning the data in <a role="doc-biblioref">JSON-LD</a> format.</li>
                <li><code>/api/classify/graph</code> - Classify the data filtered by the provided RDF class and property, returning the data as a <a role="doc-biblioref">GraphML</a> file</li>
                <li><code>/api/classify/statistics</code> - Creates statistics for classification, such as the depth of a subject-predicate pair, and the distribution of unique subjects.</li>
                <li><code>/api/classify/statistics/graph</code> - Saves the statistics of the classification operation in temporary files, using <a role="doc-biblioref">RDF Data Cube vocabulary</a>, for further downloading</li>
            </ul>
          </li>

          <li>
            Comparison Operation:
            <ul>
              <li><code>/api/compare/data</code> - Compare the data provided by two RDF classes, returning the result of the operation in various formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)</li>
              <li><code>/api/compare/html</code> - Compare the data provided by two RDF classes, returning the result of the operation in HTML format</li>
              <li><code>/api/compare/json_ld</code> - Compare the data provided by two RDF classes, returning the result of the operation in <a role="doc-biblioref">JSON-LD</a> format</li>
              <li><code>/api/compare/statistics</code> - Creates statistics for comparison operation, such as the properties of each class, which is the last/most used property, how many properties, which are the unique properties (that don't appear in the other class), or which are the common properties</li>
              <li><code>/api/compare/download_statistics</code> - This endpoint allows you to download comparison statistics.</li>
            </ul>
          </li>

          <li>
            Alignment Operation:
            <ul>
              <li><code>/api/align/data</code> - Align the data to an ontology provided, returning the result of the operation in various formats (JSON, HTML, <a role="doc-biblioref">JSON-LD</a>)</li>
              <li><code>/api/align/html</code> - Align the data to an ontology provided, returning the result of the operation in HTML format</li>
              <li><code>/api/align/json_ld</code> - Align the data to an ontology provided, returning the result of the operation in <a role="doc-biblioref">JSON-LD</a> format</li>
              <li><code>/api/align/table</code> - Align the data to an ontology provided, returning the result of the operation in JSON format, to further create a table</li>
              <li><code>/api/align/statistics</code> - Create statistics for alignment operation, namely the average measure of the alignment</li>
              <li><code>/api/align/statistics/graph</code> - Creates statistics in <a role="doc-biblioref">RDF Data Cube vocabulary</a> for alignment operation, and saves the results in a temporary file for further downloading</li>
            </ul>
          </li>

          <li>
            Other endpoints:
            <ul>
                <li><code>/api/download-stats</code> - Sends the file as an attachment, where the file name is sent as parameter; it is used in Classification and Alignment operations</li>
            </ul>
          </li>
      </ol>

      <p>
        Below are some example requests for each operation:
      </p>

      <figure typeof="schema:SoftwareSourceCode">
        <pre>
          <code>
            # Examples for Visualization
        
  
          
            # Example of GET request to the main classification endpoint
            GET /api/classify?class=AdministrativeArea&property=schema:address
            Accept: */*
            Response:
            [
                {
                    "blankNode": "https://archiipedia.com/#PostalAddress",
                    "initial_predicate": "http://schema.org/address",
                    "initial_subject": "https://archiipedia.com/#AdministrativeArea",
                    "level1_object": "http://schema.org/PostalAddress",
                    "level1_predicate": "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"
                },
                {
                    "blankNode": "https://archiipedia.com/#PostalAddress",
                    "initial_predicate": "http://schema.org/address",
                    "initial_subject": "https://archiipedia.com/#AdministrativeArea",
                    "level1_object": "india",
                    "level1_predicate": "http://schema.org/addressCountry"
                }
              ...
            ]
          
            
              # Example of GET request to the properties endpoint
              GET /api/properties?class=AdministrativeArea
              Accept: */*
              Response:
              [
                  "rdf:type",
                  "schema:address",
                  "schema:containsPlace",
                  "schema:geo",
                  "schema:name",
                  "schema:url",
                  "schema:hasMap",
                  "schema:mainEntityOfPage",
                  "schema:sameAs"
              ]
  
          
            # Examples for Comparison
          
  
         
            # Example of GET request to the main alignment endpoint
            GET api/align?target=schema.org
            Accept: */*
            Response:
            C:\Users\ENBYSE~1\AppData\Local\Temp\tmpe_ck29uf.nt
  
            # Example of GET request to the results table generated for alignment operation
            GET api/align/table?target=schema.org
            Accept: */*
            Response:
            "results": [
                          {
                              "alignedEntity": "https://schema.org/Mountain",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/Mountain",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/JobPosting",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/JobPosting",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/State",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/State",
                              "relation": "="
                          },
                          {
                              "alignedEntity": "https://schema.org/Brand",
                              "measure": "0.99",
                              "originalEntity": "http://schema.org/Brand",
                              "relation": "="
                          }
                          ...
                        ]
          </code>
        </pre>
      </figure>

    </section>

    <section id="rdf-models">
      <h2>RDF-based Knowledge Models</h2>
      <ul>
        <li>Modelele rdf, cum s-au utilizat</li>
        <li>detalii despre ontologia folosita</li>
      </ul>
    </section>

    <section id="external-sources">
      <h2>External Data/Knowledge Sources</h2>
      <ul>
        <li>daca folosim date externe de pe Wikidata, DBPedia</li>
        <li>exemple de SPARQL Queries pentru a le extrage</li>
        <li>Linked Data concepts?</li>
        <li>cum sunt integrate aceste date in aplicatie</li>
      </ul>
    </section>

    <section id="user-guide">
      <h2>User Guide</h2>
      <ul>
        <li>descrierea interfetei, cu print screens</li>
        <li>exemple de utilizare</li>
        <li>functionalitatile cheie ale aplicatiei</li>
      </ul>
    </section>

    <section id="demonstration">
      <h2>Demonstration</h2>
      <p>
        link la demo
      <p>
      <p>
        A demonstration of the WATR application is available at the following link:
        <a>WATR Demo</a>
      </p>
    </section>

    <section id="conclusions">
      <h2>Conclusions and Future Perspectives</h2>
      <p>
        provocari, realizari
      <p>
    </section>
  </body>
</html>
